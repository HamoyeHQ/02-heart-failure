{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest_DecisionTree_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXTBvU399aOa"
      },
      "source": [
        "**Important**\n",
        "\n",
        "in this notebook, i noticed that that the dataset was quite small it has only 299 observations which is quite small to perform a test train split and train a good model. Also there is a very high class imbalance in the dependent variable(DEATH_EVENT) so i performed an upsample of the dataset by SMOTING to equate the amount of classes in the dependent variable.\n",
        "\n",
        "The following processes were carried out as Pre-processing before training models:\n",
        "\n",
        "1. Upsampling the dataset by Smoting to increase the number of observations to 400.\n",
        "\n",
        "2. Use of columns transformer to transform some columns using MinMaxScaler transformer.\n",
        "3. perform Grid search hyper-parameter tunning for DecisionTreeClassifier and RandomForestClassifier.\n",
        "4. fitting the models, making predictons and evaluating the metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvH0EVPuhPjZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import Series, DataFrame"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvj7kfvghh7K",
        "outputId": "36933acf-b413-4d98-b924-215057db2916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "dataset = pd.read_csv('https://raw.githubusercontent.com/gogzicole/stage-f-07-heart-failure/master/data/heart_failure_clinical_records_dataset.csv')\n",
        "dataset.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0  75.0        0                       582  ...        0     4            1\n",
              "1  55.0        0                      7861  ...        0     6            1\n",
              "2  65.0        0                       146  ...        1     7            1\n",
              "3  50.0        1                       111  ...        0     7            1\n",
              "4  65.0        1                       160  ...        0     8            1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ2NGReijUcf",
        "outputId": "8cc867b0-f186-480f-b9e3-97e8abd4ae8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(299, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X57xKKH2l1B9",
        "outputId": "00719bb0-a3dc-461b-c527-df853d42aab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# selecting feature matrix and target variable\n",
        "X = dataset.drop(columns = 'DEATH_EVENT')\n",
        "y = dataset['DEATH_EVENT']\n",
        "y.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    203\n",
              "1     96\n",
              "Name: DEATH_EVENT, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBSd4HIDAVaE"
      },
      "source": [
        "As we can see in the DEATH_EVENT column the instances of 1 and 0 are very much far apart, so creating a model using this data in this form would most likely get a high accuracy score but would fail in its precision and recall score. This model being for medical use we would have less concerne with the accuracy score but the precision and mostly recall.\n",
        "\n",
        "This is because we want less instances of FN which is evedent of a high recall score. we also want less instances of FP which is evident of high precision, but we cant have both a high precision and high recall at the same time as they are inversely proportional, so we would also aim to have a high f1_score which is the harmonic mean of recall and precision.\n",
        "\n",
        "i would demonstrate this by first building a model with the dataset as it is and then calculate the metrics. then i would perform Smotin and then build another model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1312wq-CHsh"
      },
      "source": [
        "**First models Without Smoting**\n",
        "\n",
        "**RandomForestclassifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IdL2dynH8z4"
      },
      "source": [
        "i would be using sklearn pipelines to encapsulate the whole steps in a pipe to make the work a little bit messy and wit less blocks of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lquhwi-sCSD7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import  ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSW3Yh2wCR9x"
      },
      "source": [
        "make_column_transformer = [2,4,6,7,8,11]\n",
        "\n",
        "pipe = Pipeline([('col_transform', ColumnTransformer(remainder = 'passthrough',\n",
        "                transformers = [('scaler',MinMaxScaler(),make_column_transformer)])),\n",
        "                ('grid_search',GridSearchCV(RandomForestClassifier(),\n",
        "                {'max_depth':range(1,15), 'n_estimators': [50, 100,300,500],\n",
        "                'max_features': ['auto', 'sqrt', 'log'], \n",
        "                'min_samples_split': [2,3,5,7,9],'min_samples_leaf': [1,2,4,6,8]},\n",
        "                cv = 3, n_jobs = 2, scoring = 'accuracy', verbose = 1))])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka0Gs5ZqcJyH"
      },
      "source": [
        "Xt1 = pipe.named_steps['col_transform'].fit_transform(X)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLqNNFJsYylp"
      },
      "source": [
        "x_train, x_test,y_train, y_test = train_test_split(Xt1, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V_ANU4bCR33",
        "outputId": "bef7892a-1fbe-4b2e-c283-3bdc09b2ee55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "pipe.fit(x_train,y_train)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4200 candidates, totalling 12600 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   54.3s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed:  9.4min\n",
            "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=2)]: Done 4046 tasks      | elapsed: 15.2min\n",
            "[Parallel(n_jobs=2)]: Done 4996 tasks      | elapsed: 18.7min\n",
            "[Parallel(n_jobs=2)]: Done 6046 tasks      | elapsed: 22.6min\n",
            "[Parallel(n_jobs=2)]: Done 7196 tasks      | elapsed: 26.2min\n",
            "[Parallel(n_jobs=2)]: Done 8446 tasks      | elapsed: 31.2min\n",
            "[Parallel(n_jobs=2)]: Done 9796 tasks      | elapsed: 36.0min\n",
            "[Parallel(n_jobs=2)]: Done 11246 tasks      | elapsed: 41.5min\n",
            "[Parallel(n_jobs=2)]: Done 12600 out of 12600 | elapsed: 46.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('col_transform',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('scaler',\n",
              "                                                  MinMaxScaler(copy=True,\n",
              "                                                               feature_range=(0,\n",
              "                                                                              1)),\n",
              "                                                  [2, 4, 6, 7, 8, 11])],\n",
              "                                   verbose=False)),\n",
              "                ('grid_search',\n",
              "                 GridSearchCV(cv=3, error_score=nan,\n",
              "                              estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                               ccp_alp...\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False),\n",
              "                              iid='deprecated', n_jobs=2,\n",
              "                              param_grid={'max_depth': range(1, 15),\n",
              "                                          'max_features': ['auto', 'sqrt',\n",
              "                                                           'log'],\n",
              "                                          'min_samples_leaf': [1, 2, 4, 6, 8],\n",
              "                                          'min_samples_split': [2, 3, 5, 7, 9],\n",
              "                                          'n_estimators': [50, 100, 300, 500]},\n",
              "                              pre_dispatch='2*n_jobs', refit=True,\n",
              "                              return_train_score=False, scoring='accuracy',\n",
              "                              verbose=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meTze0p0CRw_",
        "outputId": "9299e4cf-a4d1-4a51-c341-b9548ddcc138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "model1 = pipe.named_steps['grid_search'].best_estimator_\n",
        "model1.fit(x_train, y_train)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=6, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=2, min_samples_split=3,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzqafkYQCRe7"
      },
      "source": [
        "y_pred1 = model1.predict(x_test)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIRY7LBoCRY-",
        "outputId": "78641c74-3b2f-470b-86a5-275b22f8eb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, recall_score, accuracy_score,precision_score, f1_score\n",
        "report1 = classification_report(y_test,y_pred1)\n",
        "print('The classification report for the Dataset as it is:')\n",
        "print(report1)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The classification report for the Dataset as it is:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.95      0.88        37\n",
            "           1       0.88      0.65      0.75        23\n",
            "\n",
            "    accuracy                           0.83        60\n",
            "   macro avg       0.85      0.80      0.81        60\n",
            "weighted avg       0.84      0.83      0.83        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOkwmVVlCRPm",
        "outputId": "538f2359-d651-4f58-87d1-46319030913f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "recall = recall_score(y_test,y_pred1)\n",
        "accuracy = accuracy_score(y_test,y_pred1)\n",
        "precision = precision_score(y_test,y_pred1)\n",
        "f1score = f1_score(y_test,y_pred1)\n",
        "print('the Recall is:{}'.format(round(recall,4)))\n",
        "print(f'the Accuracy is:{round(accuracy,4)}')\n",
        "print('the Precision is: %s' %(round(precision,4)))\n",
        "print(f'the F1_score is: {f1score}')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the Recall is:0.6522\n",
            "the Accuracy is:0.8333\n",
            "the Precision is: 0.8824\n",
            "the F1_score is: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKIHAE_2qAU5"
      },
      "source": [
        "As we can see the model performed quite poorly with a precision of 88% and a recall of about 65% this is quite poor and unacceptable.\n",
        "\n",
        "Now we would train another model using the same hyparameters on grid search and on an umsampled dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uKF104LrpHJ"
      },
      "source": [
        "**First Model with SMOTING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y-ixDsUBpIg",
        "outputId": "268e5311-a43b-497a-8668-4a793e92428a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#perform Smote on X and y and reassign the new variables to x_balanced and ya_balanced\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=1)\n",
        "X_balanced, y_balanced = smote.fit_sample(X, y)\n",
        "X_balanced = DataFrame(X_balanced, columns = X.columns)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66oe5_CbENdb",
        "outputId": "c79586b2-3bd4-4cb7-dda3-e9ad2d8507f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# we can see that the numbr of observations increased from 299 to 406\n",
        "# and also both instances of 1 and 0 in y are now equal\n",
        "print('the shape of X is: {}'.format(X.shape))\n",
        "print('the shape of y is: {}'.format(y.shape))\n",
        "print('the shape of X_balanced is: {}'.format(X_balanced.shape))\n",
        "print('the shape of y_balanced is: {}'.format(Series(y_balanced).shape))\n",
        "print('the instances of 1 and 0 in DEATH_EVENT are:')\n",
        "print(Series(y_balanced).value_counts())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the shape of X is: (299, 12)\n",
            "the shape of y is: (299,)\n",
            "the shape of X_balanced is: (406, 12)\n",
            "the shape of y_balanced is: (406,)\n",
            "the instances of 1 and 0 in DEATH_EVENT are:\n",
            "1    203\n",
            "0    203\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whAgAIgnyYsM"
      },
      "source": [
        "**Random Forest Classifier on SMOTED data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgSa672WkpmJ",
        "outputId": "49a1a071-252b-4b87-b773-282288948292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "# I would perform MinMaxScaling using ColumnTransform to passthrough some columns\n",
        "# Also i would perform GridSearchCV for the RandomForestClassifier\n",
        "# The whole process would be encapsulated in an sklearn pipeline.\n",
        "\n",
        "make_column_transformer = [2,4,6,7,8,11] # This variable specifies the columns that would be scaled, while the rest are passthrough\n",
        "\n",
        "pipe5 = Pipeline([('col_transform', ColumnTransformer(remainder = 'passthrough',\n",
        "                transformers = [('scaler',MinMaxScaler(),make_column_transformer)])),\n",
        "                ('grid_search',GridSearchCV(RandomForestClassifier(),\n",
        "                {'max_depth':range(1,15), 'n_estimators': [50, 100,300,500],\n",
        "                'max_features': ['auto', 'sqrt', 'log'], \n",
        "                'min_samples_split': [2,3,5,7,9],'min_samples_leaf': [1,2,4,6,8]},\n",
        "                cv = 3, n_jobs = 2, scoring = 'accuracy', verbose = 1))])\n",
        "\n",
        "Xt5 = pipe.named_steps['col_transform'].fit_transform(X_balanced) #fitting and transforming the smoted feature matrix to the transformer\n",
        "\n",
        "x_train, x_test,y_train, y_test = train_test_split(Xt5, y_balanced, test_size = 0.2, random_state = 0)\n",
        "\n",
        "pipe5.fit(x_train,y_train) # perfoming the GridSearchCV by calling the pipe fit method"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4200 candidates, totalling 12600 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   54.5s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed:  9.3min\n",
            "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=2)]: Done 4046 tasks      | elapsed: 15.2min\n",
            "[Parallel(n_jobs=2)]: Done 4996 tasks      | elapsed: 18.8min\n",
            "[Parallel(n_jobs=2)]: Done 6046 tasks      | elapsed: 22.7min\n",
            "[Parallel(n_jobs=2)]: Done 7196 tasks      | elapsed: 26.4min\n",
            "[Parallel(n_jobs=2)]: Done 8446 tasks      | elapsed: 31.5min\n",
            "[Parallel(n_jobs=2)]: Done 9796 tasks      | elapsed: 36.3min\n",
            "[Parallel(n_jobs=2)]: Done 11246 tasks      | elapsed: 42.0min\n",
            "[Parallel(n_jobs=2)]: Done 12600 out of 12600 | elapsed: 46.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('col_transform',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('scaler',\n",
              "                                                  MinMaxScaler(copy=True,\n",
              "                                                               feature_range=(0,\n",
              "                                                                              1)),\n",
              "                                                  [2, 4, 6, 7, 8, 11])],\n",
              "                                   verbose=False)),\n",
              "                ('grid_search',\n",
              "                 GridSearchCV(cv=3, error_score=nan,\n",
              "                              estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                               ccp_alp...\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False),\n",
              "                              iid='deprecated', n_jobs=2,\n",
              "                              param_grid={'max_depth': range(1, 15),\n",
              "                                          'max_features': ['auto', 'sqrt',\n",
              "                                                           'log'],\n",
              "                                          'min_samples_leaf': [1, 2, 4, 6, 8],\n",
              "                                          'min_samples_split': [2, 3, 5, 7, 9],\n",
              "                                          'n_estimators': [50, 100, 300, 500]},\n",
              "                              pre_dispatch='2*n_jobs', refit=True,\n",
              "                              return_train_score=False, scoring='accuracy',\n",
              "                              verbose=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgxOovMbkqJj"
      },
      "source": [
        "model5 = pipe5.named_steps['grid_search'].best_estimator_ #Training the RandomForestClassifier with the best parameters from the search\n",
        "model5.fit(x_train, y_train)\n",
        "y_pred5 = model5.predict(x_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9SlEJ-TkqmM",
        "outputId": "e61c00cd-7c0e-4a28-c63f-5cec99ec4654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, recall_score, accuracy_score,precision_score, f1_score\n",
        "recall5 = recall_score(y_test,y_pred5)\n",
        "accuracy5 = accuracy_score(y_test,y_pred5)\n",
        "precision5 = precision_score(y_test,y_pred5)\n",
        "f1score5 = f1_score(y_test,y_pred5)\n",
        "print('the Recall for smoted RandomForest is:{}'.format(round(recall5,4)))\n",
        "print(f'the Accuracy for smoted RandomForest is:{round(accuracy5,4)}')\n",
        "print('the Precision for smoted RandomForest is: %s' %(round(precision5,4)))\n",
        "print(f'the F1_score for smoted RandomForest is: {round(f1score5,4)}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the Recall for smoted RandomForest is:0.9574\n",
            "the Accuracy for smoted RandomForest is:0.9024\n",
            "the Precision for smoted RandomForest is: 0.8824\n",
            "the F1_score for smoted RandomForest is: 0.9184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGILvUT7DVHU"
      },
      "source": [
        "# saving the model to Disk\n",
        "import dill\n",
        "with open('RandomForest.dill','wb') as f:\n",
        "  dill.dump(model5,f)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJtLgkcrEFYF",
        "outputId": "ffa37c8a-5ae9-4adf-dc2d-6ef35bb3f59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#checking if model is saved successfully on disk\n",
        "!ls -alh RandomForest.dill"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 298K Oct 24 00:43 RandomForest.dill\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY2ryVf5UjU2"
      },
      "source": [
        "**Decision Tree Classifier on SMOTE dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqiDlAYX0asp"
      },
      "source": [
        "I would perform the same process here also, but without a pipeline so u can better understand the steps carried out using pipeline.\n",
        "\n",
        "there would be no need to perform scaling on the dataset again as i would be using the already scaled dataset from the previous model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZlP-oOj3yM3",
        "outputId": "9bc8808b-f1a7-416f-f8e5-6088fe412a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "grid6 = GridSearchCV(DecisionTreeClassifier(),{'max_depth':range(1,300),\n",
        "                    'max_features': ['auto', 'sqrt', 'log'], 'min_samples_split': range(10,400,10),\n",
        "                    'min_samples_leaf':[1,2,4,6,8],'max_depth':[2,4,6,8,50]},\n",
        "                    cv = 3, n_jobs = 2, scoring = 'accuracy', verbose = 1)\n",
        "grid6.fit(x_train,y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2925 candidates, totalling 8775 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done 2812 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=2)]: Done 8772 out of 8775 | elapsed:    8.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 8775 out of 8775 | elapsed:    8.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=2,\n",
              "             param_grid={'max_depth': [2, 4, 6, 8, 50],\n",
              "                         'max_features': ['auto', 'sqrt', 'log'],\n",
              "                         'min_samples_leaf': [1, 2, 4, 6, 8],\n",
              "                         'min_samples_split': range(10, 400, 10)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_fM_myRVF_-",
        "outputId": "5ece0066-d681-42ef-b45b-0c608d206dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "model6 = grid1.best_estimator_\n",
        "model6.fit(x_train,y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=6, min_samples_split=10,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kONh1KfyVT4T",
        "outputId": "ee26608b-b663-4f86-c4de-0347597323bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "y_pred6 = model6.predict(x_test)\n",
        "from sklearn.metrics import classification_report\n",
        "report6 = classification_report(y_test,y_pred6)\n",
        "print(report6)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85        35\n",
            "           1       0.89      0.87      0.88        47\n",
            "\n",
            "    accuracy                           0.87        82\n",
            "   macro avg       0.86      0.86      0.86        82\n",
            "weighted avg       0.87      0.87      0.87        82\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcBv0XD-YehN",
        "outputId": "98b3898d-35f8-4fb2-fda8-a95c0f09dd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "recall6 = recall_score(y_test,y_pred6)\n",
        "accuracy6 = accuracy_score(y_test,y_pred6)\n",
        "precision6 = precision_score(y_test,y_pred6)\n",
        "f1score6 = f1_score(y_test,y_pred6)\n",
        "print('the Recall for smoted DecisionTree is:{}'.format(round(recall6,4)))\n",
        "print(f'the Accuracy for smoted DecisionTree is:{round(accuracy6,4)}')\n",
        "print('the Precision for smoted DecisionTree is: %s' %(round(precision6,4)))\n",
        "print(f'the F1_score for smoted DecisionTree is: {round(f1score6,4)}')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the Recall for smoted DecisionTree is:0.8723\n",
            "the Accuracy for smoted DecisionTree is:0.8659\n",
            "the Precision for smoted DecisionTree is: 0.8913\n",
            "the F1_score for smoted DecisionTree is: 0.8817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PXxY9BQE0G-"
      },
      "source": [
        "**Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArsxJ4RBE6_K"
      },
      "source": [
        "as we can see the RandomForest model on the SMOTE dataset has the best performance metrics and should be selected as the model of choice.\n",
        "\n",
        "its hyperparameters are listed below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9GLyTJIA_cZ",
        "outputId": "bf5a417a-9f76-45b3-becf-b028f72ecdc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "pipe5.named_steps['grid_search'].best_params_ "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 9,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 3,\n",
              " 'n_estimators': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O1eHW33E_JL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}